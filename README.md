# Snap Circuit Computer Vision System üîßü§ñ

A comprehensive computer vision pipeline for analyzing Snap Circuit boards using YOLOv8 object detection, OpenCV connection detection, and NetworkX graph analysis with TD-BKT integration.

## üß† System Overview

This system provides real-time analysis of Snap Circuit boards through:

- **Component Detection**: YOLOv8-based identification of circuit pieces (LEDs, batteries, wires, etc.)
- **Connection Analysis**: OpenCV-based wire tracing and component connection detection  
- **Circuit State Inference**: NetworkX graph analysis to determine if circuits are closed, powered, and functional
- **Live Circuit Visualization**: Automatic generation of beautiful circuit board visualizations in real-time
- **Graph Format Output**: TD-BKT compatible graph format for downstream algorithms
- **Real-time Processing**: Live camera feed analysis with annotated output

## üöÄ Quick Start

### Prerequisites

- Python 3.8+
- OpenCV-compatible camera (for real-time mode)
- CUDA-compatible GPU (recommended for faster inference)

### Installation

1. **Clone and setup environment:**
```bash
git clone <repository-url>
cd robotics-research
pip install -r requirements.txt
```

2. **Test basic functionality:**
```bash
python main.py --mode camera --no-save
```

## üìÅ Project Structure (Cleaned & Organized)

```
robotics-research/
‚îú‚îÄ‚îÄ main.py                    # Main application entry point
‚îú‚îÄ‚îÄ config.py                  # Configuration settings
‚îú‚îÄ‚îÄ data_structures.py         # Core data classes
‚îú‚îÄ‚îÄ requirements.txt           # Dependencies
‚îú‚îÄ‚îÄ README.md                  # This file
‚îú‚îÄ‚îÄ snap_circuit_image.jpg     # Test image
‚îú‚îÄ‚îÄ train_improved_model.py    # Model training script
‚îÇ
‚îú‚îÄ‚îÄ models/                    # AI Models
‚îÇ   ‚îú‚îÄ‚îÄ component_detector.py  # YOLOv8 component detection
‚îÇ   ‚îî‚îÄ‚îÄ weights/               # Trained model files
‚îÇ       ‚îî‚îÄ‚îÄ snap_circuit_yolov8.pt
‚îÇ
‚îú‚îÄ‚îÄ vision/                    # Computer Vision
‚îÇ   ‚îî‚îÄ‚îÄ connection_detector.py # OpenCV connection detection  
‚îÇ
‚îú‚îÄ‚îÄ circuit/                   # Circuit Analysis
‚îÇ   ‚îî‚îÄ‚îÄ graph_builder.py      # NetworkX circuit analysis
‚îÇ
‚îú‚îÄ‚îÄ live_circuit_visualizer.py # Live visualization generator
‚îÇ
‚îú‚îÄ‚îÄ utils/                     # Utilities (Less frequently used)
‚îÇ   ‚îú‚îÄ‚îÄ setup_improved_training.py
‚îÇ   ‚îú‚îÄ‚îÄ create_individual_component_dataset.py
‚îÇ   ‚îú‚îÄ‚îÄ expand_training_dataset.py
‚îÇ   ‚îú‚îÄ‚îÄ data_preparation.py
‚îÇ   ‚îî‚îÄ‚îÄ COMPONENT_PHOTO_GUIDE.md
‚îÇ
‚îú‚îÄ‚îÄ data/                      # Training & Test Data
‚îÇ   ‚îú‚îÄ‚îÄ individual_components/ # Component photos
‚îÇ   ‚îú‚îÄ‚îÄ augmented_training/    # Augmented dataset
‚îÇ   ‚îî‚îÄ‚îÄ expanded_training/     # Expanded dataset
‚îÇ
‚îú‚îÄ‚îÄ output/                    # System Outputs
‚îÇ   ‚îú‚îÄ‚îÄ frames/               # Annotated video frames
‚îÇ   ‚îú‚îÄ‚îÄ data/                 # JSON outputs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ detection_*.json  # Traditional format
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ graph_*.json      # TD-BKT graph format
‚îÇ   ‚îú‚îÄ‚îÄ live_circuit_visual_*.png  # Timestamped visualizations
‚îÇ   ‚îî‚îÄ‚îÄ latest_circuit_visual.png  # Most recent visualization
‚îÇ
‚îú‚îÄ‚îÄ snap_circuit_training/     # Training Results
‚îÇ   ‚îî‚îÄ‚îÄ expanded_snap_circuit_model/
‚îÇ       ‚îî‚îÄ‚îÄ weights/
‚îÇ           ‚îî‚îÄ‚îÄ best.pt
‚îÇ
‚îî‚îÄ‚îÄ Graph Format Integration   # NEW: TD-BKT Integration
    ‚îú‚îÄ‚îÄ circuit_graph_format.py    # Graph data structures
    ‚îî‚îÄ‚îÄ graph_output_converter.py  # Detection ‚Üí Graph converter
```

## üéØ Usage

### Real-time Camera Analysis

```bash
# Basic real-time detection (outputs JSON + live visualizations)
python main.py --mode camera

# Use specific camera and custom model
python main.py --mode camera --camera 1 --model models/weights/snap_circuit_yolov8.pt

# Disable display for headless operation
python main.py --mode camera --no-display

# The system will automatically:
# ‚úÖ Process frames every 3 seconds
# ‚úÖ Generate live circuit visualizations (PNG files)
# ‚úÖ Save detection data (JSON files)
# ‚úÖ Display real-time annotated camera feed
```

**Real-time Controls:**
- `q`: Quit
- `s`: Save current frame
- `p`: Pause/resume detection
- `+/-`: Adjust processing interval

### üé® Live Circuit Visualization

The system automatically generates beautiful circuit board visualizations in real-time:

**üîÑ Automatic Generation**: 
- Processes camera feed every 3 seconds
- Creates PNG visualizations automatically
- No manual intervention required

**üì∏ Visual Features**:
- **Hexagonal grid background** mimicking actual snap circuit boards
- **Color-coded components** with distinct colors for each type:
  - Battery holders (blue), LEDs (pink), switches (teal)
  - Buttons (green), wires (gold), motors (purple)
  - Resistors (red), speakers (magenta), and 10+ other types
- **Connection lines** showing component relationships
- **Component labels** with confidence scores
- **Circuit status** indicating if circuit is complete and powered
- **Timestamp information** for each visualization

**üìÅ Output Files**:
```bash
output/live_circuit_visual_[timestamp].png  # Timestamped versions
output/latest_circuit_visual.png           # Always the most recent
```

**üéØ Features**:
- Real-time digital twin of your snap circuit board
- Intelligent connection detection between nearby components
- High-confidence component filtering (>75% confidence)
- Actual layout based on camera-detected positions

### Video File Processing

```bash
# Process video file
python main.py --mode video --input video.mp4 --output annotated_video.mp4
```

### Single Image Analysis

```bash
# Analyze single image
python main.py --mode image --input circuit_image.jpg
```

## üìä Dual Output Format

The system now outputs **both** traditional JSON and graph format:

### Traditional Format (`detection_*.json`)
```json
{
  "connection_graph": {
    "components": [...],
    "edges": [...],
    "state": {...}
  },
  "processing_time": 0.045
}
```

### Graph Format (`graph_*.json`) - TD-BKT Compatible
```json
{
  "graph": {
    "directed": true,
    "nodes": [
      {
        "id": "battery_holder_0",
        "component_type": "battery_holder",
        "position": {"x": 200, "y": 300},
        "accessibility": 0.95,
        "placement_correctness": 0.9
      }
    ],
    "edges": [...],
    "circuit_analysis": {
      "connectivity": {...},
      "circuit_complete": false,
      "power_sources": [...]
    }
  }
}
```

## üèãÔ∏è Training Your Own Model

### 1. Individual Component Dataset
```bash
# Create individual component dataset
python utils/create_individual_component_dataset.py

# Follow photo guide
cat utils/COMPONENT_PHOTO_GUIDE.md
```

### 2. Train Improved Model
```bash
python train_improved_model.py
```

### 3. Use Trained Model
```bash
python main.py --mode camera --model snap_circuit_training/expanded_snap_circuit_model/weights/best.pt
```

## üîß Component Classes

The system detects these Snap Circuit components:

- **Power**: `battery_holder`
- **Outputs**: `led`, `speaker`, `motor`, `lamp`, `fan`, `buzzer`, `alarm`
- **Inputs**: `button`, `switch`, `photoresistor`, `microphone`
- **Passive**: `resistor`, `wire`, `connection_node`
- **Complex**: `music_circuit`

## ‚öôÔ∏è Configuration

Key settings in `config.py`:

```python
# Performance optimized for real-time
VIDEO_CONFIG = {
    "processing_interval": 3.0,  # Process every 3 seconds (optimized for visualization)
    "resolution": [1920, 1080],
    "fps": 30
}

# YOLO Detection
YOLO_CONFIG = {
    "confidence_threshold": 0.5,
    "device": "cuda"  # Uses GPU if available
}

# Live Visualization
VISUALIZATION_CONFIG = {
    "confidence_threshold": 0.75,  # Only show high-confidence components
    "connection_tolerance": 35,     # Pixel distance for connection detection
    "save_latest": True            # Always save latest_circuit_visual.png
}
```

## üéØ Integration with TD-BKT Systems

The graph format outputs are designed for TD-BKT (Temporal Difference - Bayesian Knowledge Tracing) algorithms:

- **Spatial positioning** for robot guidance
- **Component accessibility** scores
- **Circuit connectivity** analysis
- **No built-in recommendations** (handled by external TD-BKT system)

## üßπ Recent Cleanup

**Removed obsolete files:**
- Old test scripts (`test_*.py`)
- Demo scripts (`demo_*.py`) 
- Summary scripts (`final_results_summary.py`)
- Duplicate training scripts
- Unused model files (`yolo11n.pt`, `yolov8n.pt`, `yolov8x.pt`)
- Old detection data files

**Organized structure:**
- Core system files in root
- Utilities moved to `utils/` directory
- Clear separation of concerns

## üìà Performance

- **Real-time detection**: ~1-2 seconds per frame
- **GPU accelerated**: 10-20x faster training
- **Optimized connection detection**: Limited path processing for performance
- **Dual output**: Traditional + graph format without performance impact

## ü§ù Contributing

1. The system is production-ready with clean codebase
2. Graph format integration complete for TD-BKT consumption
3. Training pipeline optimized for individual component photos
4. Real-time performance optimized for practical use

---

**System Status**: ‚úÖ Production Ready | Graph Integration Complete | Live Visualization Active | Performance Optimized
